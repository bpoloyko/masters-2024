# masters-2024

# Список использованных источников информации
| Источник  | Second Header |
| ------------- | ------------- |
| [Stemming and Lemmatization](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)  | Описывает приемы, которые помогают сопоставить несколько слов с общим корневым словом. Таким образом, эти слова обрабатываются одинаково, и модель узнает, что их можно использовать в схожих контекстах.  |
| [Tensorflow for text](https://www.tensorflow.org/text/tutorials/text_generation)  | Описываются основы генерации текста в Python  |
| https://aclanthology.org/D14-1162.pdf|Описания алгоритма векторизации слов GloVe |
|https://openai.com/research|Не конкретный источник, набор статей от openAI о различных подходах к построению NLP моделей|
|Tf-idf weighting (stanford.edu)|Описание алгоритма TF-IDF (оценки важности слова в контексте документа)|
|Python for data science: VanderPlas J. Python data science handbook : essential tools for working with data. — Sebastopol, CA : O’Reilly Media, Inc, 2016. — ISBN 978- 1491912058.|Содержит основы работы с данными в python, основы построения моделей машинного обучения
|https://web.stanford.edu/~jurafsky/slp3/4|Обоснование применения наивного байесовского классификатора для решения задач NLP|
|[seq2seq]https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/|Описывает построение модели seq2seq для генерации краткого содержания|
|https://fabianofalcao.medium.com/metrics-for-evaluating-summarization-of-texts-performed-by-transformers-how-to-evaluate-the-b3ce68a309c3|Метрики, используемые для оценки эффективности моделей генерации сокращенного содержания|
|[PyTorch]https://huggingface.co/learn/nlp-course/chapter7/5?fw=pt|Использование библиотеки PyTorch|
|https://paperswithcode.com/dataset/mlsum|Датасет mlsum и модели, обученные на нем|
|[MathBERT](https://arxiv.org/abs/2105.00377)|Статья, описывающая, как обрабатывать математические формулы при составлении краткого содержания|
















